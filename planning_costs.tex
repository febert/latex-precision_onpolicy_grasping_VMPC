\vspace{-0.1cm}
\section{Planning Costs}
\label{sec:planning_costs}
\vspace{-0.2cm}

Registration can fail when distances between objects in the images are large. During a trajectory the registration to the first image typically becomes harder while the registration to goal-image usually becomes easier. Here we propose a mechanism that estimates which image is registered correctly, allowing us to utilize only the successful registration for evaluating the planning cost. By estimating which registration is more accurate we can give a high weight $\lambda_i$ to pixel-distance costs $c_i$ associated with a designated pixel $\hat{d}_{i,t}$ that is tracked successfully and a low, ideally zero, weight to a designated pixel where the registration is poor. We propose to use the photometric distance between the true frame and the warped frame evaluated at $d_{0,i}$ and $d_{g,i}$ as an estimate for \emph{local} registration success. A low photometric error indicates that the registration network predicted a flow vector leading to a pixel with a similar color, thus indicating warping success. However this does not necessarily mean that the flow vector points to the correct location. For example, there could be several objects with the same color and the network could simply point to the wrong object. Letting $I_i(d_i)$ denote the pixel value in image $I_i$ for position $d_i$, and $\hat{I}_i(d_i)$ denote the corresponding pixel in the image warped by the registration function, we can define the general weight factors $\lambda_i$ as
\begin{align}
\lambda_i =  \frac{||I_i(d_i) - \hat{I_i}(d_i)||_2^{-1}}{\sum^N_j ||I_j(d_j) - \hat{I}_j(d_j)||^{-1}_2}.
\label{eqn:cost_avg}
\end{align}
where $\hat{I}_i = \hat{F}_{i \leftarrow t} \diamond I_t$. The MPC cost is computed as the average of the costs $c_i$ weighted by $\lambda_i$, where each $c_i$ is the expected distance (see \autoref{eq:cost}) between the registered point $\hat{d}_{i,t}$ and the goal point $d_{g,i}$. Hence, the cost used for planning is $c = \sum_i \lambda_i c_i$.  In the case of the single view model and a single designated pixel, the index $i$ iterates over the start and goal image (and $N=2$).

The proposed weighting scheme can also be used with multiple designated pixels, as used in multi-task settings and multi-view models (as explained in section \ref{sec:scalingup}). The index $i$ then also loops over the views and indices of the designated pixels. 

