\vspace{-0.1cm}
\section{Planning Costs}
\vspace{-0.2cm}
As shown in the previous section, registration can fail when distances between objects in the images are large. Here we propose a mechanism that estimates which image is registered correctly, allowing us to utilize only the successful registration for evaluating the planning cost.
When registering to both start and goal-image or when using more than one view, every pair of designated pixel and goal pixel defines a cost function (the expected distance to to the goal). As the robot approaches the goal, the difference to the initial image increases, making it increasingly harder to register. However, the difference to the goal image (hopefully) decreases, making it easier to register.
We exploit this to compute accurate costs for all stages of the task by using a weighting factor that gives a high weight to the designated pixels $\hat{d}_{i,t}$ that are successfully tracked and a low (ideally zero) weight to the designated pixels where the registration is poor. We propose to use the photometric distance (we found that the norm in RGB space works well) between the true frame and the warped frame as an estimate for \emph{local} registration success. A low photometric error indicates that the registration network predicted a flow vector leading to a pixel with a similar color, thus indicating warping success. However this does not necessarily mean that the flow vector points to the correct location. For example, there could be several objects with the same color and the network could simply point to the wrong object. Letting $I_i(d_i)$ denote the pixel value in image $I_i$ for position $d_i$, and $\hat{I}_i(d_i)$ denote the corresponding pixel in the image warped by the registration function (i.e., $\hat{I}_i = \hat{F}_{i \leftarrow t} \diamond I_t$, where $I_t$ is the current image), we can define the general weight factors $\lambda_i$ as
\begin{align}
\lambda_i =  \frac{||I_i(d_i) - \hat{I_i}(d_i)||_2^{-1}}{\sum^N_j ||I_j(d_j) - \hat{I}_j(d_j)||^{-1}_2}.
\label{eqn:cost_avg}
\end{align}
In the case of the single view model and a single designated pixel, the index $i$ iterates over the start and goal image (and $N=2$), in the case of multi-view models or multiple designated pixels the index also loops over the views and indices of the designated pixels. 
The MPC cost is then computed as the average of the costs $c_i$ weighted by $\lambda_i$, where each $c_i$ is the expected distance (see \autoref{eq:cost}) between the registered point $\hat{d}_{i,t}$ and the goal point $d_{g,i}$, where the registered point is found by $\hat{d}_{i,t} = d_i + \hat{F}_{i \leftarrow t}(d_i)$ (analogous to \autoref{eqn:warped_pos}). Finally the cost used for planning is $c = \sum_i \lambda_i c_i$.
